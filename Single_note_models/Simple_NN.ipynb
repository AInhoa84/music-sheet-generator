{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import regularizers\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Utilities/data_note.tsv\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x15991</th>\n",
       "      <th>x15992</th>\n",
       "      <th>x15993</th>\n",
       "      <th>x15994</th>\n",
       "      <th>x15995</th>\n",
       "      <th>x15996</th>\n",
       "      <th>x15997</th>\n",
       "      <th>x15998</th>\n",
       "      <th>x15999</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>-0.015286</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>-0.005293</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>C#3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.013210</td>\n",
       "      <td>-0.014460</td>\n",
       "      <td>-0.016820</td>\n",
       "      <td>-0.016346</td>\n",
       "      <td>-0.013873</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>-0.014268</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.003954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017439</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.023198</td>\n",
       "      <td>-0.019781</td>\n",
       "      <td>-0.015293</td>\n",
       "      <td>-0.012494</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.012630</td>\n",
       "      <td>D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.009459</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.008832</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>-0.010718</td>\n",
       "      <td>-0.002320</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001679</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>D#3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.021950</td>\n",
       "      <td>0.020994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>-0.009846</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>-0.016278</td>\n",
       "      <td>-0.014461</td>\n",
       "      <td>-0.012089</td>\n",
       "      <td>-0.009292</td>\n",
       "      <td>-0.008961</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016608</td>\n",
       "      <td>-0.018866</td>\n",
       "      <td>-0.018244</td>\n",
       "      <td>-0.014823</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.010667</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.005703</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>-0.017786</td>\n",
       "      <td>-0.018655</td>\n",
       "      <td>-0.018373</td>\n",
       "      <td>-0.018204</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.017219</td>\n",
       "      <td>-0.015150</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>F3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.001465  0.001681  0.005331 -0.002838 -0.015286 -0.009736  0.015490   \n",
       "1 -0.008995 -0.013210 -0.014460 -0.016820 -0.016346 -0.013873 -0.015907   \n",
       "2 -0.009459 -0.008396 -0.008832 -0.012935 -0.010718 -0.002320 -0.002686   \n",
       "3  0.009730  0.016409  0.019472  0.015838  0.014779  0.016792  0.015904   \n",
       "4 -0.016608 -0.018866 -0.018244 -0.014823 -0.010421 -0.010667 -0.005970   \n",
       "\n",
       "         x7        x8        x9  ...    x15991    x15992    x15993    x15994  \\\n",
       "0  0.010337  0.001405  0.002371  ...  0.003449  0.003488  0.001495 -0.001752   \n",
       "1 -0.014268 -0.007894 -0.003954  ... -0.017439 -0.021490 -0.023198 -0.019781   \n",
       "2 -0.000303  0.002634  0.000839  ... -0.001679 -0.001041 -0.000368  0.002192   \n",
       "3  0.019331  0.021950  0.020994  ... -0.005104 -0.009846 -0.014612 -0.016278   \n",
       "4 -0.000487 -0.005703 -0.009161  ... -0.017657 -0.017786 -0.018655 -0.018373   \n",
       "\n",
       "     x15995    x15996    x15997    x15998    x15999  Note  \n",
       "0 -0.002831 -0.002337 -0.002936 -0.005293 -0.007221   C#3  \n",
       "1 -0.015293 -0.012494 -0.012988 -0.014049 -0.012630    D3  \n",
       "2  0.005376  0.007840  0.006027  0.003115  0.003368   D#3  \n",
       "3 -0.014461 -0.012089 -0.009292 -0.008961 -0.012282    E3  \n",
       "4 -0.018204 -0.018803 -0.017219 -0.015150 -0.011934    F3  \n",
       "\n",
       "[5 rows x 16001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Note\"] = librosa.note_to_midi(data[\"Note\"]) - 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x15991</th>\n",
       "      <th>x15992</th>\n",
       "      <th>x15993</th>\n",
       "      <th>x15994</th>\n",
       "      <th>x15995</th>\n",
       "      <th>x15996</th>\n",
       "      <th>x15997</th>\n",
       "      <th>x15998</th>\n",
       "      <th>x15999</th>\n",
       "      <th>Note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>-0.002838</td>\n",
       "      <td>-0.015286</td>\n",
       "      <td>-0.009736</td>\n",
       "      <td>0.015490</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.002371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>-0.002831</td>\n",
       "      <td>-0.002337</td>\n",
       "      <td>-0.002936</td>\n",
       "      <td>-0.005293</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008995</td>\n",
       "      <td>-0.013210</td>\n",
       "      <td>-0.014460</td>\n",
       "      <td>-0.016820</td>\n",
       "      <td>-0.016346</td>\n",
       "      <td>-0.013873</td>\n",
       "      <td>-0.015907</td>\n",
       "      <td>-0.014268</td>\n",
       "      <td>-0.007894</td>\n",
       "      <td>-0.003954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017439</td>\n",
       "      <td>-0.021490</td>\n",
       "      <td>-0.023198</td>\n",
       "      <td>-0.019781</td>\n",
       "      <td>-0.015293</td>\n",
       "      <td>-0.012494</td>\n",
       "      <td>-0.012988</td>\n",
       "      <td>-0.014049</td>\n",
       "      <td>-0.012630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.009459</td>\n",
       "      <td>-0.008396</td>\n",
       "      <td>-0.008832</td>\n",
       "      <td>-0.012935</td>\n",
       "      <td>-0.010718</td>\n",
       "      <td>-0.002320</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.002634</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001679</td>\n",
       "      <td>-0.001041</td>\n",
       "      <td>-0.000368</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.005376</td>\n",
       "      <td>0.007840</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.003368</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.016409</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>0.015838</td>\n",
       "      <td>0.014779</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.021950</td>\n",
       "      <td>0.020994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005104</td>\n",
       "      <td>-0.009846</td>\n",
       "      <td>-0.014612</td>\n",
       "      <td>-0.016278</td>\n",
       "      <td>-0.014461</td>\n",
       "      <td>-0.012089</td>\n",
       "      <td>-0.009292</td>\n",
       "      <td>-0.008961</td>\n",
       "      <td>-0.012282</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016608</td>\n",
       "      <td>-0.018866</td>\n",
       "      <td>-0.018244</td>\n",
       "      <td>-0.014823</td>\n",
       "      <td>-0.010421</td>\n",
       "      <td>-0.010667</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.000487</td>\n",
       "      <td>-0.005703</td>\n",
       "      <td>-0.009161</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>-0.017786</td>\n",
       "      <td>-0.018655</td>\n",
       "      <td>-0.018373</td>\n",
       "      <td>-0.018204</td>\n",
       "      <td>-0.018803</td>\n",
       "      <td>-0.017219</td>\n",
       "      <td>-0.015150</td>\n",
       "      <td>-0.011934</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 16001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.001465  0.001681  0.005331 -0.002838 -0.015286 -0.009736  0.015490   \n",
       "1 -0.008995 -0.013210 -0.014460 -0.016820 -0.016346 -0.013873 -0.015907   \n",
       "2 -0.009459 -0.008396 -0.008832 -0.012935 -0.010718 -0.002320 -0.002686   \n",
       "3  0.009730  0.016409  0.019472  0.015838  0.014779  0.016792  0.015904   \n",
       "4 -0.016608 -0.018866 -0.018244 -0.014823 -0.010421 -0.010667 -0.005970   \n",
       "\n",
       "         x7        x8        x9  ...    x15991    x15992    x15993    x15994  \\\n",
       "0  0.010337  0.001405  0.002371  ...  0.003449  0.003488  0.001495 -0.001752   \n",
       "1 -0.014268 -0.007894 -0.003954  ... -0.017439 -0.021490 -0.023198 -0.019781   \n",
       "2 -0.000303  0.002634  0.000839  ... -0.001679 -0.001041 -0.000368  0.002192   \n",
       "3  0.019331  0.021950  0.020994  ... -0.005104 -0.009846 -0.014612 -0.016278   \n",
       "4 -0.000487 -0.005703 -0.009161  ... -0.017657 -0.017786 -0.018655 -0.018373   \n",
       "\n",
       "     x15995    x15996    x15997    x15998    x15999  Note  \n",
       "0 -0.002831 -0.002337 -0.002936 -0.005293 -0.007221     0  \n",
       "1 -0.015293 -0.012494 -0.012988 -0.014049 -0.012630     1  \n",
       "2  0.005376  0.007840  0.006027  0.003115  0.003368     2  \n",
       "3 -0.014461 -0.012089 -0.009292 -0.008961 -0.012282     3  \n",
       "4 -0.018204 -0.018803 -0.017219 -0.015150 -0.011934     4  \n",
       "\n",
       "[5 rows x 16001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(df, target_column):\n",
    "    return df.drop(target_column, axis=1), df[target_column]\n",
    "\n",
    "def split_data(df, target_column):\n",
    "    X_train, y_train = create_xy(df.sample(round(0.8*df.shape[0])), target_column)\n",
    "    df = df.drop(X_train.index)\n",
    "    X_val, y_val = create_xy(df.sample(round(0.5*df.shape[0])), target_column)\n",
    "    df = df.drop(X_val.index)\n",
    "    X_test, y_test = create_xy(df, target_column)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(data, \"Note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\anaconda\\envs\\tfm\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(16000,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(35, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\anaconda\\envs\\tfm\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      " - 2s - loss: 3.1651 - acc: 0.4000\n",
      "Epoch 2/5\n",
      " - 1s - loss: 1.7264 - acc: 0.8071\n",
      "Epoch 3/5\n",
      " - 1s - loss: 0.9732 - acc: 0.8696\n",
      "Epoch 4/5\n",
      " - 1s - loss: 0.5964 - acc: 0.9179\n",
      "Epoch 5/5\n",
      " - 1s - loss: 0.3502 - acc: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f18746a20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA:  - 0s 559us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation accuracy: 0.7285714302744184\n"
     ]
    }
   ],
   "source": [
    "print('Cross-validation accuracy:', val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      13       13\n",
      "      18       18\n",
      "      20        8\n",
      "      29       26\n",
      "       2        2\n",
      "      13       13\n",
      "      32       32\n",
      "       9        9\n",
      "      10       10\n",
      "       3        3\n",
      "       3        3\n",
      "      12       12\n",
      "      29       29\n",
      "      23       11\n",
      "       9       28\n",
      "      30       18\n",
      "      18       18\n",
      "      23       23\n",
      "      18       18\n",
      "      33       33\n",
      "       5        5\n",
      "       4        4\n",
      "       9       33\n",
      "       2        2\n",
      "      14        2\n",
      "       7        7\n",
      "      11       11\n",
      "      11       11\n",
      "      14       14\n",
      "      16       16\n",
      "      15       27\n",
      "       9       28\n",
      "       7        7\n",
      "      16       16\n",
      "      22       34\n",
      "       2        2\n",
      "      21       33\n",
      "       6        6\n",
      "       4        4\n",
      "      15       15\n",
      "      17       17\n",
      "       2        2\n",
      "       8        8\n",
      "      12        0\n",
      "       3        3\n",
      "      12        0\n",
      "      23       23\n",
      "      14       14\n",
      "       0        0\n",
      "      15       15\n",
      "       7        7\n",
      "      19        7\n",
      "      29       14\n",
      "      31       31\n",
      "      13       25\n",
      "       0       12\n",
      "      28       28\n",
      "      11       11\n",
      "       1        1\n",
      "      12       12\n",
      "      30       30\n",
      "      24       24\n",
      "      22       22\n",
      "      23       23\n",
      "      15       15\n",
      "       8        8\n",
      "      24       24\n",
      "      15       27\n",
      "      29       17\n",
      "       1        1\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(model.predict(X_val), axis=1)\n",
    "\n",
    "for i, j in zip(predictions, y_val):\n",
    "    print(\"{:>8} {:>8}\".format(i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4803d90eaf77478bb3748b98789f27b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - ETA:  - 0s 602us/step\n",
      "70/70 [==============================] - ETA:  - 0s 731us/step\n",
      "70/70 [==============================] - ETA:  - 0s 859us/step\n",
      "70/70 [==============================] - ETA:  - 0s 974us/step\n",
      "70/70 [==============================] - ETA:  - 0s 1ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 1ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 1ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 1ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 2ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 3ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 4ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 5ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 6ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 0s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 7ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 8ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 8ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 8ms/step\n",
      "70/70 [==============================] - ETA:  - 1s 8ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Model score')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC8AAAF3CAYAAACFVGEAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X2Y5XddH/z3Z2d358DOzvKQzSwSSEJNUYoaMUSo9aFSveNdb+DqhZqoxaLXRa1iLa22eFcp0tte9W69sVp8QC34gKSYSuVqo9EKPrSlQAIRCBQMQZs0ZJMQkuxMnLN7Zr73H+c3YbKZ3Z2Hc+ac3Xm9rmuund/3/H6/8zmb77WT33u+D9VaCwAAAMC02jfpAgAAAADORngBAAAATDXhBQAAADDVhBcAAADAVBNeAAAAAFNNeAEAAABMNeEFAAAAMNWEFwAAAMBUE14AAAAAU014AQAAAEy1/ZMuYDdcdNFF7bLLLpt0GQAAAMA6t9xyy/2ttaPnOm9PhBeXXXZZbr755kmXAQAAAKxTVX++mfNMGwEAAACmmvACAAAAmGrCCwAAAGCqCS8AAACAqSa8AAAAAKaa8AIAAACYasILAAAAYKoJLwAAAICpJrwAAAAApprwAgAAAJhqwgsAAABgqu2fdAGwZrCymvd96oH0V1YnXQoAAMB556983nwuPtybdBljIbxgatx02/F8769/YNJlAAAAnJd+7tufl2ue+7RJlzEWwgumxv2L/STJL3/n1Znv6ZoAAABbcflFhyZdwth4QmRqLPYHSZIvv/wp6R2YmXA1AAAATAsLdjI1FvuDHJipzO7XLQEAAPgcT4lMjaX+IIdm96eqJl0KAAAAU0R4wdRYXB7k0EEzmQAAAHgs4QVTY7E/yGELdQIAAHAa4QVTY+nkcNoIAAAArCe8YGosLg8yJ7wAAADgNMILpsZiX3gBAADA4wkvmBpL/ZUcmp2ZdBkAAABMGeEFU2M48uLApMsAAABgyggvmAqrqy1LJweZM/ICAACA0wgvmAqPnFpJa7HbCAAAAI8jvGAqLPUHSZK5nvACAACAxxJeMBUW18ILIy8AAAA4jfCCqbC4PAwvDh0UXgAAAPBYwgumgmkjAAAAnInwgqlg2ggAAABnIrxgKggvAAAAOBPhBVNhbdqIrVIBAAA4nfCCqbDYX0li5AUAAACPJ7xgKiz2T2VmX6V3QJcEAADgsTwpMhWW+is5dHAmVTXpUgAAAJgywgumwonlgSkjAAAAbEh4wVRY6g8y1xNeAAAA8HhjDS+q6pqq+nhV3V5Vr9ng9TdU1a3d1yeq6sHTXp+vqv9dVf92XduXVdWHu3v+VJlncEFYOjmw0wgAAAAbGlt4UVUzSd6Y5BuSPCfJdVX1nPXntNZe3Vq7srV2ZZKfTvKbp93mnyf5w9PafjbJK5Nc0X1dM4by2WWmjQAAAHAm4xx5cXWS21trd7TWTia5PslLznL+dUnetnZQVV+WZCHJ765re1qS+dbae1prLcmvJHnpOIpndy31hRcAAABsbJzhxdOT3Lnu+K6u7XGq6tIklyd5V3e8L8lPJPnBDe5512buyfllqW/aCAAAABsbZ3ix0VoU7QznXpvkhtbaSnf8PUlubK3dedp5m75nVb2yqm6uqpvvu+++TRXM5Jww8gIAAIAzGOfT4l1JnrHu+JIkd5/h3GuTfO+64xcm+cqq+p4kc0kOVtVikn/T3eec92ytvSnJm5LkqquuOlNowhRorZk2AgAAwBmN82nx/UmuqKrLk/zvDAOKbz39pKp6dpInJ3nPWltr7dvWvf53klzVWntNd3yiql6Q5L1JXp7hQp+cx5ZPrWa1xbQRAAAANjS2aSOttUGSVyW5KcnHkry9tXZbVb2+ql687tTrklzfLcC5GX8vyS8muT3JJ5P89gjLZgJO9E8lSeZ6wgsAAAAeb6xPi621G5PceFrba087ft057vGWJG9Zd3xzkueOqkYmb6k/XOpkbnZmwpUAAAAwjca5YCdsyuLyIEly6KCRFwAAADye8IKJW+wPwwvTRgAAANiI8IKJW1oLLyzYCQAAwAaEF0zc2sgLu40AAACwEeEFE7cWXhwWXgAAALAB4QUTt2TkBQAAAGchvGDiFvuDVCVPPGirVAAAAB5PeMHELfYHmTu4P1U16VIAAACYQsILJm6pPzBlBAAAgDMSXjBxi/1B5nrCCwAAADYmvGDiFvsrRl4AAABwRsILJm5x+VTmZi3WCQAAwMaEF0zcUn8lc0ZeAAAAcAbCCyZu0YKdAAAAnIXwgolb7A+MvAAAAOCMhBdMVGstS8ILAAAAzkJ4wUT1B6sZrDbTRgAAADgj4QUTtdgfJEkO94QXAAAAbEx4wUQtdeHFoYPCCwAAADYmvGCi1kZemDYCAADAmQgvmKjFZdNGAAAAODvhBRO1dNLICwAAAM5OeMFEnehGXszNzky4EgAAAKaV8IKJWuqvJEnmZg9MuBIAAACmlfCCiXp0txEjLwAAADgD4QUTdcJWqQAAAJyD8IKJWuoPcujgTPbtq0mXAgAAwJQSXjBRS/2BnUYAAAA4K+EFE3WiP8hcT3gBAADAmQkvmKil/iBzRl4AAABwFsILJmq45oXwAgAAgDMTXjBRJ5ZNGwEAAODshBdM1NJJ00YAAAA4O+EFE7W4PMih2ZlJlwEAAMAUE14wUUv9lczNHph0GQAAAEwx4QUT0x+s5OTKauaMvAAAAOAshBdMzFJ/JUlyyJoXAAAAnIXwgolZ6g+SxIKdAAAAnJXwgolZFF4AAACwCcILJubR8KInvAAAAODMhBdMzFp4Yc0LAAAAzkZ4wcRY8wIAAIDNEF4wMYvLwgsAAADObazhRVVdU1Ufr6rbq+o1G7z+hqq6tfv6RFU92LVfWlW3dO23VdV3r7vmD7p7rl138Tg/A+Nj2ggAAACbMbanxqqaSfLGJF+X5K4k76+qd7bWPrp2Tmvt1evO/74kX9odfjrJX22t9atqLslHumvv7l7/ttbazeOqnd3xaHhxcGbClQAAADDNxjny4uokt7fW7mitnUxyfZKXnOX865K8LUlaaydba/2ufXbMdTIhS/1BnnBgJvtn/OcFAADgzMb51Pj0JHeuO76ra3ucqro0yeVJ3rWu7RlV9aHuHj++btRFkry5mzLyI1VVoy+d3bDYXzFlBAAAgHMaZ3ixUajQznDutUluaK2tPHpia3e21r44yecn+Y6qWuhe+rbW2hcl+cru629v+OZVr6yqm6vq5vvuu2/bH4LxWewPMjdryggAAABnN87w4q4kz1h3fEmSu89w7rXppoycrhtxcVuGQUVaa/+7+/NEkl/PcHrKRte9qbV2VWvtqqNHj27rAzBeS/1B5npGXgAAAHB24wwv3p/kiqq6vKoOZhhQvPP0k6rq2UmenOQ969ouqaondN8/OclXJPl4Ve2vqou69gNJvjHJR8b4GRijxf4ghw4KLwAAADi7sT05ttYGVfWqJDclmUny71prt1XV65Pc3FpbCzKuS3J9a239lJIvTPITVdUynH7yr1trH66qQ0lu6oKLmST/JckvjOszMF6Ly4N83pN6ky4DAACAKTfWX3u31m5McuNpba897fh1G1z3e0m+eIP2pSRfNtoqmZSlkwMLdgIAAHBO9qhkYpb6wgsAAADOTXjBxJxYHuSw8AIAAIBzEF4wEadWVtMfrBp5AQAAwDkJL5iIpf4gSYQXAAAAnJPwgolY7MIL00YAAAA4F+EFE7HUX0li5AUAAADnJrxgIhb7p5Ikh2ZnJlwJAAAA0054wUQsdiMvDveMvAAAAODshBdMhAU7AQAA2CzhBROxuDwML+aEFwAAAJyD8IKJWNttRHgBAADAuQgvmAjTRgAAANgs4QUTsdgfZHb/vhyY0QUBAAA4O0+OTMRif2DKCAAAAJsivGAiFvsDU0YAAADYFOEFE7Fk5AUAAACbJLxgIkwbAQAAYLOEF0zEcNrIzKTLAAAA4DwgvGAilvormesdmHQZAAAAnAeEF0zEcNqIkRcAAACcm/CCiVhctuYFAAAAmyO8YNetrLb8xakVW6UCAACwKcILdt3SyUGSGHkBAADApggv2HWLy8ILAAAANk94wa5b6g/DC9NGAAAA2AzhBbvuRN/ICwAAADZPeMGuWxt5MdcTXgAAAHBuwgt23aPTRg4KLwAAADg34QW77oQFOwEAANgC4QW7zrQRAAAAtkJ4wa5bOrmSJDk0OzPhSgAAADgfCC/YdSeWBzk4sy+z+4UXAAAAnJvwgl231B8YdQEAAMCmnTO8qKFvr6rXdsfPrKqrx18aF6pheGG9CwAAADZnMyMvfibJC5Nc1x2fSPLGsVXEBe9Ef2CnEQAAADZtM0+QX95ae15VfTBJWmufraqDY66LC9iS8AIAAIAt2MzIi1NVNZOkJUlVHU2yOtaquKAtmjYCAADAFmwmvPipJO9IcnFV/ViS/5rkX4y1Ki5oi/1B5nrCCwAAADbnnE+QrbW3VtUtSV6UpJK8tLX2sbFXxgVrqT/I3EHhBQAAAJtz1ifIqtqX5EOttecm+Z+7UxIXusVl00YAAADYvLNOG2mtrSb5k6p65i7VwwVudbVl6eSKaSMAAABs2maeIJ+W5Laqel+SpbXG1tqLx1YVF6xHTq0kSeZmZyZcCQAAAOeLzYQXPzr2KtgzFpcHSZK52QMTrgQAAIDzxTl3G2mt/WGG610c7r4+1rWdU1VdU1Ufr6rbq+o1G7z+hqq6tfv6RFU92LVfWlW3dO23VdV3r7vmy6rqw909f6qqarMflslb7A/Di0NGXgAAALBJ5wwvquqbk7wvyTcl+eYk762ql23iupkkb0zyDUmek+S6qnrO+nNaa69urV3ZWrsyyU8n+c3upU8n+atd+5cneU1VfV732s8meWWSK7qva875KZkaS/21kRfWvAAAAGBzNvME+U+TPL+1dm+SVNXRJP8lyQ3nuO7qJLe31u7orrs+yUuSfPQM51+X5J8lSWvt5Lr22XQhS1U9Lcl8a+093fGvJHlpkt/exOdgCiwKLwAAANiic468SLJvLbjofGaT1z09yZ3rju/q2h6nqi5NcnmSd61re0ZVfai7x4+31u7urr9rM/dkOn1u2ojwAgAAgM3ZzBPk71TVTUne1h1/SzY30mGjtSjaGc69NskNrbWVR09s7c4kX9xNF/mPVXXDVu5ZVa/McHpJnvlMO71Oi88t2Cm8AAAAYHM2s2DnDyb5+SRfnORLkryptfaPN3Hvu5I8Y93xJUnuPsO51+Zz4cjp7393ktuSfGV3z0s2c8/W2ptaa1e11q46evToJsplNyyd7MKLnvACAACAzdnMgp2XJ7mxtfYPW2uvznAkxmWbuPf7k1xRVZdX1cEMA4p3bnD/Zyd5cpL3rGu7pKqe0H3/5CRfkeTjrbVPJzlRVS/odhl5eZLf2kQtTAlrXgAAALBVm1m74jeSrK47Xunazqq1NkjyqiQ3JflYkre31m6rqtdX1YvXnXpdkutba+unf3xhhrua/EmSP0zyr1trH+5e+3tJfjHJ7Uk+GYt1nlcWlweZ2VeZ3b+ZrgcAAACbW/Ni//rdP1prJ7uRFOfUWrsxyY2ntb32tOPXbXDd72U4TWWje96c5LmbeX+mz1J/kLnZ/RkOnAEAAIBz28yvv+9bP1Kiql6S5P7xlcSFbLG/YsoIAAAAW7KZp8jvTvLWqvq3Ge72cWeGa03Ali32TwkvAAAA2JJzPkW21j6Z5AVVNZekWmsnxl8WF6ql/koOzc5MugwAAADOI5vZbeT7q2o+yVKSN1TVB6rq68dfGheixf4gh4y8AAAAYAs2s+bFd7bWHk7y9UkuTvKKJP9yrFVxwVrsD3K4J7wAAABg8zYTXqxtC/F/Jnlza+1P1rXBliz1Bzl0UHgBAADA5m0mvLilqn43w/Dipqo6nGR1vGVxoVpcNm0EAACArdnMU+R3JbkyyR2ttUeq6qkZTh2BLWmtZemkaSMAAABszWZ2G1lN8oF1x59J8plxFrXXray2nFrZ2eCW2f37UjVds3v+4tRKVluMvAAAAGBLPEVOof/+yfvzt3/pfTu6x8tfeGle/5Lnjqii0VhcHiQRXgAAALA1niKn0GVPPZR/fM2zt339f7jlrtx654MjrGg0FvvD8OKw8AIAAIAtOONTZFU95WwXttYeGH05JMkznvLEfM/XfP62r/+z+5fyBx+/b4QVjcZSfyWJkRcAAABszdmeIm9J0rLxtqgtybPGUhE7tjDfy/2L/QxWVrN/ZjMbyuyOE/1TSZI54QUAAABbcManyNba5btZCKOzMN/LakvuXzyZY0d6ky7nUWsjL4QXAAAAbMU5fy1fQ99eVT/SHT+zqq4ef2ls17H5YWBxz8PLE67ksZb6awt2zky4EgAAAM4nm5lT8DNJXpjkW7vjE0neOLaK2LG10RbHpyy8ONGFF3M9Iy8AAADYvM08RX55a+15VfXBJGmtfbaqDo65Lnbg4vnZJNMXXqyNvDBtBAAAgK3YzMiLU1U1k+Einamqo0lWx1oVO3LRodns31e556HpCi8WlwfZV8kTDpg2AgAAwOZtJrz4qSTvSHJxVf1Ykv+a5F+MtSp2ZN++ysWHZ6duzYvF/iCHZvenaqMNbAAAAGBj5xy/31p7a1XdkuRFGW6b+tLW2sfGXhk7cvF8L/c+3J90GY+x1B+YMgIAAMCWnfFJsqqesu7w3iRvW/9aa+2BcRbGzhyb7+X2+xYnXcZjrI28AAAAgK0425PkLRmuc1FJnpnks933T0ryv5JcPvbq2LZjR3r5b7ffP+kyHmPRyAsAAAC24YxrXrTWLm+tPSvJTUn+r9baRa21pyb5xiS/uVsFsj0L872c6A8e3eFjGpg2AgAAwHZsZsHO57fWblw7aK39dpKvHl9JjMLCFG6XauQFAAAA27GZ8OL+qvrhqrqsqi6tqn+a5DPjLoydOTbfS5Kp2nFkqb9izQsAAAC2bDPhxXVJjma4Xep/THJx18YUWzgyDC+mb+TFzKTLAAAA4Dyzma1SH0jy/VU1n2S1tTZdW1iwoYX5tfBiOrZLba0Nw4uekRcAAABszTlHXlTVF1XVB5N8OMltVXVLVT13/KWxE3Oz+zM3uz/3PDQdIy/6g9WsrDbTRgAAANiyzUwb+fkk/7C1dmlr7dIk/yjJm8ZbFqOwMD87NdNGTiwPdz2xYCcAAABbtZnw4lBr7d1rB621P0hyaGwVMTLHjvSmZsHOtS1bhRcAAABs1WbCizuq6ke63UYuq6ofTvKpcRfGzi0c7uXeKVnzYrELL0wbAQAAYKs2E158Z4a7jfxmhjuOHE3yinEWxWgsHOnl+MPLWV1tky7l0fDCyAsAAAC2ajO7jXw2yd/fhVoYsWPzvQxWWz6zdDJHD89OtBbTRgAAANiuMz5JVtU7z3Zha+3Foy+HUfrcdqnLEw8vTBsBAABgu872JPnCJHcmeVuS9yapXamIkVmYHwYWxx9eznOffmSitayFF4d7wgsAAAC25mxPkseSfF2S65J8a5L/nORtrbXbdqMwdu7YkeHIi2nYcWTJyAsAAAC26YwLdrbWVlprv9Na+44kL0hye5I/qKrv27Xq2JGjc7PZV8nxhyYfXiz2V5IkTzwwM+FKAAAAON+c9dfgVTWb5G9mOPrisiQ/leGuI5wH9s/sy0Vzszk+BdulLi4PMje7P/v2mX0EAADA1pxtwc5fTvLcJL+d5Edbax/ZtaoYmYX53tRMGzk0a9QFAAAAW3e2kRd/O8lSkr+c5O9XPfob80rSWmvzY66NEViY7+Wuzz4y6TKy2B9Y7wIAAIBtOePTZGvtjOthcP44dmQ2N//5A5MuI4v9QQ4LLwAAANgGAcUFbuFwLw8+cirLp1YmWseSkRcAAABsk/DiArfQbZd674QX7TRtBAAAgO0aa3hRVddU1cer6vaqes0Gr7+hqm7tvj5RVQ927VdW1Xuq6raq+lBVfcu6a95SVZ9ad92V4/wM57tj88PwYtKLdpo2AgAAwHaN7WmyqmaSvDHJ1yW5K8n7q+qdrbWPrp3TWnv1uvO/L8mXdoePJHl5a+1Pq+rzktxSVTe11h7sXv/B1toN46r9QnKsG3lxfMLhhWkjAAAAbNc4R15cneT21todrbWTSa5P8pKznH9dkrclSWvtE621P+2+vzvJvUmOjrHWC9bC4ekILxb7g8z1hBcAAABs3TjDi6cnuXPd8V1d2+NU1aVJLk/yrg1euzrJwSSfXNf8Y910kjdU1ezoSr7wzD9hf3oH9uWehyYXXvQHKzm10jJn5AUAAADbMM7wojZoa2c499okN7TWHrMlRlU9LcmvJnlFa221a/6hJF+Q5PlJnpLkn2z45lWvrKqbq+rm++67bzv1XxCqKsfmexNd82KpP/zPeujgzMRqAAAA4Pw1zvDiriTPWHd8SZK7z3DutemmjKypqvkk/znJD7fW/sdae2vt022on+TNGU5PeZzW2ptaa1e11q46enRvzzi5eL430d1GFpcHSZK53oGJ1QAAAMD5a5zhxfuTXFFVl1fVwQwDineeflJVPTvJk5O8Z13bwSTvSPIrrbXfOO38p3V/VpKXJvnI2D7BBWLSIy8W+114MWvkBQAAAFs3tvCitTZI8qokNyX5WJK3t9Zuq6rXV9WL1516XZLrW2vrp5R8c5KvSvJ3NtgS9a1V9eEkH05yUZL/Z1yf4UJx7MgwvHjsX/HuWQsv7DYCAADAdoz1abK1dmOSG09re+1px6/b4LpfS/JrZ7jn146wxD1hYb6Xk4PVPPjIqTz50MFdf/+lR0deCC8AAADYunFOG2FKLMwPN2Q5fmIyU0cWhRcAAADsgPBiDzg230uSiW2XatoIAAAAOyG82AMWuvDi+IQW7Xx02khPeAEAAMDWCS/2gIvXpo1MaLvUR0deHBReAAAAsHXCiz1gdv9MnnLo4MS2S11cHuSJB2cys68m8v4AAACc34QXe8TCfC/HJ7TmxdLJgfUuAAAA2DbhxR5xbH52ciMv+it2GgEAAGDbhBd7xMJ8b3JrXiyfEl4AAACwbcKLPWJhvpfPLPVzamV11997qb+SQ7Mzu/6+AAAAXBiEF3vEsSO9tJbce2L3R1+c6A+MvAAAAGDbhBd7xLH5XpLk+ATWvVgSXgAAALADwos94uL52SSZyI4jS327jQAAALB9wos9Ym3kxSR2HDnRH2SuJ7wAAABge4QXe8RTDh3MwZl9ux5enFpZzcnBauYOCi8AAADYHuHFHlFVuXh+Nvfu8napS/1Bkpg2AgAAwLYJL/aQhfle7tnlNS9OLA/DC9NGAAAA2C7hxR5ybL6367uNLJ3swgsjLwAAANgm4cUesjDfyz0PL6e1tmvvubhs2ggAAAA7I7zYQxbmZ/PIyZUsdutQ7Ia19zLyAgAAgO0SXuwhx44Mt0vdzakjS/2VJMILAAAAtk94sYcszA/Di3se2r0dRxb7p5Ikh2Zndu09AQAAuLAIL/aQY/O7P/JisRt5cXj2wK69JwAAABcW4cUe8ujIi12dNrK2YKeRFwAAAGyP8GIPecLBmcz39u/yyItBegf2Zf+MrgYAAMD2eKLcY44d6eWeh3Y3vLBYJwAAADshvNhjFuZ7OX5i9xbsXOoPckh4AQAAwA4IL/aYhfleju/myItlIy8AAADYGeHFHnNsvpf7FvtZWW278n6LRl4AAACwQ8KLPWbhSC8rqy33L+7O1BFrXgAAALBTwos9ZuHwbJLs2o4jS8ILAAAAdkh4scccO9JLkl3bcWSxv2LaCAAAADsivNhjjs0Pw4vdGnmx2D+VudmZXXkvAAAALkzCiz3mqXOzmdlXOf7w+Ne8GKysZvnUauZmD4z9vQAAALhwCS/2mJl9laNzs7lnF0ZeLJ1cSZIcMvICAACAHRBe7EELR3q7Mm1ksT9IkhzuWfMCAACA7RNe7EHH5md3ZcHOpS68sGAnAAAAOyG82IMW5nd35IXwAgAAgJ0QXuxBC/O9PLw8yF90a1KMy+JyN21EeAEAAMAOCC/2oLXtUse9aKdpIwAAAIyC8GIPOnZkGF6Me+rIiS68mBNeAAAAsAPCiz1oYX42yfjDiyXhBQAAACMgvNiDFtamjYx5xxHTRgAAABgF4cUedLh3IIcOzox9zYsT/UEOzuzLwf26GQAAANs31qfKqrqmqj5eVbdX1Ws2eP0NVXVr9/WJqnqwa7+yqt5TVbdV1Yeq6lvWXXN5Vb23qv60qv59VR0c52e4UC0c6eXeh/tjfY+l/iBzPaMuAAAA2JmxhRdVNZPkjUm+IclzklxXVc9Zf05r7dWttStba1cm+ekkv9m99EiSl7fW/kqSa5L8ZFU9qXvtx5O8obV2RZLPJvmucX2GC9nC4d4u7DaykkOzM2N9DwAAAC584xx5cXWS21trd7TWTia5PslLznL+dUneliSttU+01v60+/7uJPcmOVpVleRrk9zQXfPLSV46pvovaMeO9Ma+5sWJ5UHmZg+M9T0AAAC48I0zvHh6kjvXHd/VtT1OVV2a5PIk79rgtauTHEzyySRPTfJga21wrntydgvzvdx7Yjmrq21s77HUH2TOyAsAAAB2aJzhRW3QdqYn5WuT3NBaW3nMDaqeluRXk7yitba6lXtW1Sur6uaquvm+++7bQtl7w8L8bE6ttHz2kZNje4+lkwM7jQAAALBj4wwv7kryjHXHlyS5+wznXptuysiaqppP8p+T/HBr7X90zfcneVJVrT0Rn/GerbU3tdauaq1ddfTo0W1+hAvXsbXtUse47sXi8iBzwgsAAAB2aJzhxfuTXNHtDnIww4DinaefVFXPTvLkJO9Z13YwyTuS/Epr7TfW2ltrLcm7k7ysa/qOJL81tk9wAVs4Mgwvjo8zvOgLLwAAANi5sYUX3boUr0pyU5KPJXl7a+22qnp9Vb143anXJbm+CybWfHOSr0ryd9ZtpXpl99o/SfIPq+r2DNfA+KVxfYYL2drIi+Nj3C51sW/aCAAAADs31ifL1tqNSW48re21px2/boPrfi3Jr53hnndkuJMJO3D08GyqMrYdR1ZXWx45uWLkBQAAADs2zmlwcnWEAAARFElEQVQjTLEDM/vy1EOzY5s2snRyuCGM8AIAAICdEl7sYceOzI5twc7F/jC8MG0EAACAnRJe7GELh3tjW/NiqQsv5nrCCwAAAHZGeLGHLRzpjW3ayGJ/JUkyNzszlvsDAACwdwgv9rBj8708sHQy/cHKyO+9uLy25sWBkd8bAACAvUV4sYetbZd67ximjnxuzQsjLwAAANgZ4cUedvH8bJKMZerIo2teWLATAACAHRJe7GHHjgxHXoxjx5FF4QUAAAAjIrzYw9amjdzz0PjCC1ulAgAAsFPCiz3syBMOZHb/vtx7YjxrXuzfV5ndr4sBAACwM54s97CqysJ8bywjL5b6g8z19qeqRn5vAAAA9hbhxR53bL43tjUvDh00ZQQAAICdE17scQtHemPZbWRxeWCxTgAAAEZCeLHHLRyezfGHl9NaG+l9l04Op40AAADATgkv9rhjR3pZPrWah/9iMNL7LvZX7DQCAADASAgv9riFte1SRzx1ZHH5VA4LLwAAABgB4cUed+zIMLwY9boXS/2VHJqdGek9AQAA2JuEF3vcwuHxjLxY6g9MGwEAAGAkhBd73MXzs0mS4w+NLrxorWXx5MC0EQAAAEZCeLHH9Q7M5MlPPDDSkRePnFxJazHyAgAAgJEQXpCF+V6OP9wf2f0W+8OdS4QXAAAAjILwgi68GN3Ii7Xw4nBPeAEAAMDOCS/IsfneSKeNLK2NvDgovAAAAGDnhBdk4Ugv9y/2c2pldST3W1w2bQQAAIDREV6QhfnZtJbcvziadS9MGwEAAGCUhBfk2HwvSXLPiLZLXTpp5AUAAACjI7wgC114MapFO9emjcwJLwAAABgB4QU5dmQtvBjVtJGVJMILAAAARkN4QZ7yxIM5MFMj23FkqT/Ivkp6B3QvAAAAds7TJdm3r3Lx4V6Oj2jNi8X+IHOz+1NVI7kfAAAAe5vwgiTDHUdGNfJiLbwAAACAURBekGS4aOcoF+y00wgAAACjIrwgyVp4MZoFO5dODjLXE14AAAAwGsILkgx3HFnsD7LYH+z4XqaNAAAAMErCC5Ikx+aH26XeM4JFOxeXBzl0UHgBAADAaAgvSJJcPD+bJLl3BOteLPVNGwEAAGB0hBckWTfyYgThhWkjAAAAjJLwgiTDNS+SnYcXrTXhBQAAACMlvCBJ8sSD+3O4tz/37nDHkeVTq1ltsVUqAAAAIyO84FEL870dL9i5tlvJ3OzMKEoCAAAA4QWfc2y+t+NpI4+GFxbsBAAAYESEFzxqYb6X4zsML5a68MJWqQAAAIyK8IJHLczP5t4T/ayutm3f48Ty2rQR4QUAAACjMdbwoqquqaqPV9XtVfWaDV5/Q1Xd2n19oqoeXPfa71TVg1X1n0675i1V9al11105zs+wlxw70svKasv9S9tftHPJtBEAAABGbGxPmFU1k+SNSb4uyV1J3l9V72ytfXTtnNbaq9ed/31JvnTdLf5Vkicm+bsb3P4HW2s3jKXwPWxhfrhd6vGH+rn4cG9b91g62U0bMfICAACAERnnyIurk9zeWrujtXYyyfVJXnKW869L8ra1g9ba7yc5Mcb6OM2xtfBiB+temDYCAADAqI0zvHh6kjvXHd/VtT1OVV2a5PIk79rkvX+sqj7UTTuZ3VmZrFkbebGTHUcenTYivAAAAGBExhle1AZtZ1oJ8tokN7TWVjZx3x9K8gVJnp/kKUn+yYZvXvXKqrq5qm6+7777NlPvnnfR3MHsq52NvFjqD1KVPPHgzAgrAwAAYC8bZ3hxV5JnrDu+JMndZzj32qybMnI2rbVPt6F+kjdnOD1lo/Pe1Fq7qrV21dGjR7dQ9t61f2Zfjh6ezT0P7WDaSH+QuYP7U7VRdgUAAABbN87w4v1Jrqiqy6vqYIYBxTtPP6mqnp3kyUnes5mbVtXTuj8ryUuTfGRkFZNj870cP7Gz3UYs1gkAAMAoje0ps7U2qKpXJbkpyUySf9dau62qXp/k5tbaWpBxXZLrW2uPmVJSVX+c4fSQuaq6K8l3tdZuSvLWqjqa4bSUW5N897g+w1508Xwv/+szj2z7+qX+Sg7NmjICAADA6Iz1V+SttRuT3Hha22tPO37dGa79yjO0f+2o6uPxjs338r5PPbDt60/0B5nrHRhhRQAAAOx145w2wnno2JFeHvqLU1k+tZm1Ux9vqT/InJEXAAAAjJDFCXiMiw8Pd5592c/99xyY2Xq29T8/fSJfecVFoy4LAACAPUx4wWP8tSsuytc9Z2HbIy+uuuzJ+VvPe/qIqwIAAGAvE17wGE878oT8wsuvmnQZAAAA8ChrXgAAAABTTXgBAAAATDXhBQAAADDVhBcAAADAVBNeAAAAAFNNeAEAAABMNeEFAAAAMNWEFwAAAMBUE14AAAAAU014AQAAAEw14QUAAAAw1YQXAAAAwFQTXgAAAABTrVprk65h7KrqviR/Puk6tuiiJPdPugj2BH2N3aKvsVv0NXaLvsZu0M/YLZPqa5e21o6e66Q9EV6cj6rq5tbaVZOugwufvsZu0dfYLfoau0VfYzfoZ+yWae9rpo0AAAAAU014AQAAAEw14cX0etOkC2DP0NfYLfoau0VfY7foa+wG/YzdMtV9zZoXAAAAwFQz8gIAAACYasKLCamqf1dV91bVR9a1PaWqfq+q/rT788lde1XVT1XV7VX1oap63uQq53xTVc+oqndX1ceq6raq+v6uXX9jZKqqV1Xvq6o/6frZj3btl1fVe7t+9u+r6mDXPtsd3969ftkk6+f8U1UzVfXBqvpP3bG+xshV1Z9V1Yer6taqurlr8/OTkauqJ1XVDVX1P7v/Z3uhvsYoVdWzu3/L1r4erqp/cD71M+HF5LwlyTWntb0mye+31q5I8vvdcZJ8Q5Iruq9XJvnZXaqRC8MgyT9qrX1hkhck+d6qek70N0arn+RrW2tfkuTKJNdU1QuS/HiSN3T97LNJvqs7/7uSfLa19vlJ3tCdB1vx/Uk+tu5YX2Nc/npr7cp12wf6+ck4/Jskv9Na+4IkX5Lhv2/6GiPTWvt492/ZlUm+LMkjSd6R86ifCS8mpLX2R0keOK35JUl+ufv+l5O8dF37r7Sh/5HkSVX1tN2plPNda+3TrbUPdN+fyPCH4dOjvzFCXX9Z7A4PdF8tydcmuaFrP72frfW/G5K8qKpql8rlPFdVlyT5m0l+sTuu6GvsHj8/Gamqmk/yVUl+KUlaaydbaw9GX2N8XpTkk621P8951M+EF9NlobX26WT4wJnk4q796UnuXHfeXV0bbEk3XPpLk7w3+hsj1g3jvzXJvUl+L8knkzzYWht0p6zvS4/2s+71h5I8dXcr5jz2k0n+cZLV7vip0dcYj5bkd6vqlqp6Zdfm5yej9qwk9yV5czcd7her6lD0Ncbn2iRv674/b/qZ8OL8sNFviGwTw5ZU1VyS/5DkH7TWHj7bqRu06W+cU2ttpRuKeEmSq5N84UandX/qZ2xLVX1jkntba7esb97gVH2NUfiK1trzMhw+/b1V9VVnOVdfY7v2J3lekp9trX1pkqV8buj+RvQ1tq1bE+rFSX7jXKdu0DbRfia8mC7H14bidH/e27XfleQZ6867JMndu1wb57GqOpBhcPHW1tpvds36G2PRDXX9gwzXWHlSVe3vXlrflx7tZ93rR/L4qXSwka9I8uKq+rMk12c4XeQno68xBq21u7s/781wbvjV8fOT0bsryV2ttfd2xzdkGGboa4zDNyT5QGvteHd83vQz4cV0eWeS7+i+/44kv7Wu/eXdiq8vSPLQ2tAeOJdubvcvJflYa+3/W/eS/sbIVNXRqnpS9/0TkvyNDNdXeXeSl3Wnnd7P1vrfy5K8q7Xmt0acU2vth1prl7TWLstw2Ou7WmvfFn2NEauqQ1V1eO37JF+f5CPx85MRa63dk+TOqnp21/SiJB+NvsZ4XJfPTRlJzqN+Vn5+T0ZVvS3J1yS5KMnxJP8syX9M8vYkz0zyv5J8U2vtge7h899muDvJI0le0Vq7eRJ1c/6pqr+W5I+TfDifmx/+f2e47oX+xkhU1RdnuMjTTIbB+Ntba6+vqmdl+NvxpyT5YJJvb631q6qX5FczXIPlgSTXttbumEz1nK+q6muS/EBr7Rv1NUat61Pv6A73J/n11tqPVdVT4+cnI1ZVV2a4CPHBJHckeUW6n6fR1xiRqnpihutYPKu19lDXdt78mya8AAAAAKaaaSMAAADAVBNeAAAAAFNNeAEAAABMNeEFAAAAMNWEFwAAAMBUE14AwB5TVa2qfmLd8Q9U1etGdO+3VNXLRnGvc7zPN1XVx6rq3eN+r3PU8WdVddEkawCAvUB4AQB7Tz/J35q2h+6qmtnC6d+V5Htaa399XPUAANNDeAEAe88gyZuSvPr0F04fOVFVi92fX1NVf1hVb6+qT1TVv6yqb6uq91XVh6vqL627zd+oqj/uzvvG7vqZqvpXVfX+qvpQVf3ddfd9d1X9epIPb1DPdd39P1JVP961vTbJX0vyc1X1r047/2lV9UdVdWt3zVd27T9bVTdX1W1V9aPrzv+zqvoXVfWe7vXnVdVNVfXJqvrudTX+UVW9o6o+WlU/V1WP+3+oqvr27u/j1qr6+e4zz3R/px/pPsfj/s4BgHPbP+kCAICJeGOSD1XV/7uFa74kyRcmeSDJHUl+sbV2dVV9f5LvS/IPuvMuS/LVSf5SkndX1ecneXmSh1prz6+q2ST/rap+tzv/6iTPba19av2bVdXnJfnxJF+W5LNJfreqXtpae31VfW2SH2it3Xxajd+a5KbW2o91Izme2LX/09baA13b71fVF7fWPtS9dmdr7YVV9YYkb0nyFUl6SW5L8nPranxOkj9P8jtJ/laSG9bV+oVJviXJV7TWTlXVzyT5tu4eT2+tPbc770mb+YsGAB7LyAsA2INaaw8n+ZUkf38Ll72/tfbp1lo/ySeTrIUPH84wsFjz9tbaamvtTzMMOb4gydcneXlV3ZrkvUmemuSK7vz3nR5cdJ6f5A9aa/e11gZJ3prkq85VY5JXdGt4fFFr7UTX/s1V9YEkH0zyVzIMIta8c93neG9r7URr7b4ky+vChve11u5ora0keVuGIz/We1GGIcv7u8/4oiTP6j7/s6rqp6vqmiQPn6N+AGADRl4AwN71k0k+kOTN69oG6X65UVWV5OC61/rrvl9dd7yax/4/RTvtfVqSSvJ9rbWb1r9QVV+TZOkM9dU5P8Hpb9TaH1XVVyX5m0l+tZtW8sdJfiDJ81trn62qt2Q4smLN+s9x+mdc+1wbfabTa/3l1toPPe5DVH1Jkv8jyfcm+eYk37nVzwUAe52RFwCwR7XWHkjy9gwXv1zzZxmOIEiSlyQ5sI1bf1NV7evWwXhWko8nuSnJ36uqA0lSVX+5qg6d4z7vTfLVVXVRN93juiR/eLYLqurSJPe21n4hyS8leV6S+QwDkoeqaiHJN2zjM11dVZd3a118S5L/etrrv5/kZVV1cVfHU6rq0m5R1H2ttf+Q5Ee6egCALTLyAgD2tp9I8qp1x7+Q5Leq6n0ZPpCfaVTE2Xw8w5BhIcl3t9aWq+oXM5xa8oFuRMd9SV56tpu01j5dVT+U5N0Zjmy4sbX2W+d4769J8oNVdSrJYpKXt9Y+VVUfzHD9iTuS/LdtfKb3JPmXSb4oyR8lecdptX60qn44w3U59iU5leFIi79I8uZ1C3w+bmQGAHBu1drpox4BAFjTTW35gdbaN066FgDYq0wbAQAAAKaakRcAAADAVDPyAgAAAJhqwgsAAABgqgkvAAAAgKkmvAAAAACmmvACAAAAmGrCCwAAAGCq/f+/1a7jtyxt8AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = []\n",
    "scores = []\n",
    "\n",
    "for i in tqdm(range(100, data.shape[0], 10)):\n",
    "    n_samples.append(i)\n",
    "    x = X_train.sample(frac=1).iloc[:i]\n",
    "    y = y_train.sample(frac=1).iloc[:i]\n",
    "    model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=5, verbose=0)\n",
    "    val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "    scores.append(val_acc)\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.plot(n_samples, scores)\n",
    "plt.xlabel(\"Number of samples\")\n",
    "plt.ylabel(\"Model score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../Utilities/data-FL-Ivy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Note\"] = librosa.note_to_midi(data[\"Note\"]) - 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(data, \"Note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(16000,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(35, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 5s - loss: 3.2645 - acc: 0.3214\n",
      "Epoch 2/20\n",
      " - 3s - loss: 2.4170 - acc: 0.6310\n",
      "Epoch 3/20\n",
      " - 3s - loss: 1.8915 - acc: 0.7577\n",
      "Epoch 4/20\n",
      " - 3s - loss: 1.4796 - acc: 0.8357\n",
      "Epoch 5/20\n",
      " - 3s - loss: 1.1875 - acc: 0.8786\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.9602 - acc: 0.9107\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.8246 - acc: 0.9214\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.6846 - acc: 0.9321\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.5736 - acc: 0.9476\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.4964 - acc: 0.9595\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.4430 - acc: 0.9690\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.4275 - acc: 0.9655\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.3667 - acc: 0.9690\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.3247 - acc: 0.9774\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.3525 - acc: 0.9714\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.3837 - acc: 0.9631\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.4136 - acc: 0.9619\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.3932 - acc: 0.9685\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.3344 - acc: 0.9679\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.2797 - acc: 0.9744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f28e52b70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - ETA:  - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8723404191909953\n"
     ]
    }
   ],
   "source": [
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"../Utilities/data-piano-large.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Note\"] = librosa.note_to_midi(data[\"Note\"]) - 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = split_data(data, \"Note\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(256, input_shape=(16000,)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(35, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 4s - loss: 3.1734 - acc: 0.3587\n",
      "Epoch 2/20\n",
      " - 4s - loss: 2.1846 - acc: 0.6882\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.6760 - acc: 0.7791\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.3656 - acc: 0.8294\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.1489 - acc: 0.8622\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.9668 - acc: 0.8954\n",
      "Epoch 7/20\n",
      " - 4s - loss: 0.8451 - acc: 0.9140\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.7131 - acc: 0.9374\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.6551 - acc: 0.9448\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.6152 - acc: 0.9423\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.5346 - acc: 0.9492\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.4915 - acc: 0.9594\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.4382 - acc: 0.9682\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.3714 - acc: 0.9736\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.3541 - acc: 0.9721\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.3908 - acc: 0.9638\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.5667 - acc: 0.9428\n",
      "Epoch 18/20\n",
      " - 4s - loss: 0.5842 - acc: 0.9370\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.5362 - acc: 0.9448\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.4627 - acc: 0.9526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xa0b386f748>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=20, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82/82 [==============================] - ETA:  - 0s 844us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9146341463414634\n"
     ]
    }
   ],
   "source": [
    "print(val_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
