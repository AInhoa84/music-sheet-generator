{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to divide dataset intro train, validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xy(df, target_column):\n",
    "    \"\"\"\n",
    "    Separates features and target\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Original dataframe\n",
    "        target_column (str): Name of the target column\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe: Feature dataframe\n",
    "        Dataframe: Target dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    return df.drop(target_column, axis=1), df[target_column]\n",
    "\n",
    "def split_data(df, target_column):\n",
    "    \"\"\"\n",
    "    Splits data into test, train and validation\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): Original dataframe\n",
    "        target_column (str): Name of the target column\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Train feature dataframe\n",
    "        DataFrame: Train target dataframe\n",
    "        DataFrame: Validation feature dataframe\n",
    "        DataFrame: Validation target dataframe\n",
    "        DataFrame: Test feature dataframe\n",
    "        DataFrame: Test target dataframe\n",
    "    \"\"\"\n",
    "    X_train, y_train = create_xy(df.sample(round(0.8*df.shape[0])), target_column)\n",
    "    df = df.drop(X_train.index)\n",
    "    X_val, y_val = create_xy(df.sample(round(0.5*df.shape[0])), target_column)\n",
    "    df = df.drop(X_val.index)\n",
    "    X_test, y_test = create_xy(df, target_column)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "def load_file(file, rs):\n",
    "    \"\"\"\n",
    "    Loads an audio file into an array\n",
    "    \n",
    "    Args:\n",
    "        file (str): File name\n",
    "        \n",
    "    Returns:\n",
    "        Array: Waveform\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file, mono=False)\n",
    "    y = librosa.core.to_mono(y)\n",
    "    y = librosa.resample(y, sr, rs)\n",
    "    return y\n",
    "\n",
    "def temp_data(y, samples, norm):\n",
    "    \"\"\"\n",
    "    Extracts temporal data from a waveform\n",
    "    \n",
    "    Args:\n",
    "        y (Array): Waveform\n",
    "        samples (int): Number of samples to get from the waveform\n",
    "        norm (bool): True to perform normalization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Extracted data\n",
    "    \"\"\"\n",
    "    if norm:\n",
    "        data = pd.DataFrame({'x{}'.format(j): [y[j]/np.max(y)] for j in range(samples)})\n",
    "    else:\n",
    "        data = pd.DataFrame({'x{}'.format(j): [y[j]] for j in range(samples)})\n",
    "    return data\n",
    "\n",
    "def spectral_data(y, samples, norm):\n",
    "    \"\"\"\n",
    "    Extracts spectral data from a waveform\n",
    "    \n",
    "    Args:\n",
    "        y (Array): Waveform\n",
    "        samples (int): Number of samples to get from the waveform\n",
    "        norm (bool): True to perform normalization\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Extracted data\n",
    "    \"\"\"\n",
    "    if norm:\n",
    "        w = abs(np.fft.fft(y, n=samples*2))\n",
    "        freqs = np.fft.fftfreq(len(w))\n",
    "        data = pd.DataFrame({\"x{}\".format(j): [w[freqs >= 0][j]/max(w)] for j in range(samples)})\n",
    "    else:\n",
    "        w = abs(np.fft.fft(y, n=samples*2))\n",
    "        freqs = np.fft.fftfreq(len(w))\n",
    "        data = pd.DataFrame({\"x{}\".format(j): [w[freqs >= 0][j]] for j in range(samples)})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert audio files from a directory into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def dir_to_data(directory, function, *args):\n",
    "    \"\"\"\n",
    "    Applies a function to every file in a directory\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Name of the directory\n",
    "        function : Function that will be applied to each file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Extracted data\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    pbar = tqdm(os.listdir(directory))\n",
    "    \n",
    "    for file in pbar:\n",
    "        pbar.set_description(\"Processing %s\" % file)\n",
    "        df = function(directory + file, *args)\n",
    "        data = data.append(df)\n",
    "        \n",
    "    data = data.reset_index().drop(\"index\", axis=1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(y, n):\n",
    "    env_pos = []\n",
    "    env_neg = []\n",
    "\n",
    "    for i in range(0, len(y), n):\n",
    "        env_pos += n * [np.max(y[i:(n+i)])]\n",
    "        env_neg += n * [np.min(y[i:(n+i)])]\n",
    "        \n",
    "    return env_pos, env_neg\n",
    "\n",
    "def frontiers(y, env, k):\n",
    "    previous = np.array(env)[:-1]\n",
    "    next = np.array(env)[1:]\n",
    "    front = np.argwhere((next >= k*previous) & (next > 0.025)).flatten()\n",
    "    front = np.append(front, len(y[::-1][np.argwhere(y[::-1] >= 0.005)[0][0]:]))\n",
    "    \n",
    "    return front"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from keras.models import model_from_json\n",
    "\n",
    "def load_NN(name):\n",
    "    with open(name + \"_NN_architecture.json\", 'r') as json_file:\n",
    "        model = model_from_json(json_file.read())\n",
    "    model.load_weights(name + \"_NN_weights.h5\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_base(x, base):\n",
    "    return base * round(x/base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_window(y, size, disp, temp, norm, function, *args):\n",
    "    results = []\n",
    "    for i in tqdm(range(0, len(y)-size-disp, disp), leave = False):\n",
    "        window = y[i:i+size]\n",
    "        if temp:\n",
    "            window = temp_data(window, size, norm)\n",
    "        else:\n",
    "            window = spectral_data(window, size, norm)\n",
    "        results.append([i, function(window, *args)])\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
